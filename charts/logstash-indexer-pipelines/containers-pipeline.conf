input {
{{- if .Values.kafka.enabled }}
  
  kafka {
    bootstrap_servers => ["${KAFKA_BOOTSTRAP_SERVERS}"]
    topics => ["containers"]
    client_id => "${HOSTNAME}-contaienrs"
    group_id => "containers"
    auto_offset_reset => "latest"
    consumer_threads => 10
  }

{{ else }}  

  beats {
    port => 5044
  }
    
{{- end }}

}

filter {
  #all messages from the kafka topics are in json format
  {{- if .Values.kafka.enabled }}
    json {
      skip_on_invalid_json => false
      source => "message"
    }
  {{- end }}

  #remove ANSI Color bytes
  mutate {
    gsub => ["message", "\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[m|K]", ""]
  }

  #all application json formated logs can be parsed
  # we parse the payload of the message field for json
  {{- if .Values.logstash_indexer.json_messages }}
    json {
      skip_on_invalid_json => false
      source => "message"
      add_tag => [ "json_parsed_successful" ]
    }
  {{- end }} 


  if [logEvent][message]  {
    mutate {
       replace => { "message" => "%{[logEvent][message]}"
         remove_field => [ "%{[logEvent]}" ]
       }
    }
  }

  #in some cases we have msg instead of message holding the log
  if [msg] {
    mutate {
        replace => { "message" => "%{msg}" }
        remove_field => ["msg"]
    }
  }

  #some logs keep timestamps in ts field
  if [ts] {
    date {
        match => [ "ts", "MMM dd, yyyy @ HH:mm:ss.SSS", "ISO8601" ]
        target => "@timestamp"
        tag_on_failure => ["_dateparsefailure"]
    }
    mutate {
      remove_field => ["ts"]
    }
  }

  #some logs keep timestamps in timestamp field
  if [timestamp] {
    date {
        match => [ "timestamp", "MMM dd, yyyy @ HH:mm:ss.SSS", "ISO8601" ]
        target => "@timestamp"
        tag_on_failure => ["_dateparsefailure"]
    }
    mutate {
      remove_field => ["timestamp"]
    }
  }

 if "nginx-access" in [tags] {

  grok {
        match => { "message" => ["%{IPORHOST:[nginx][access][remote_ip]} - %{DATA:[nginx][access][user_name]} \[%{HTTPDATE:[nginx][access][time]}\] \"%{WORD:[nginx][access][method]} %{DATA:[nginx][access][url]} HTTP/%{NUMBER:[nginx][access][http_version]}\" %{NUMBER:[nginx][access][response_code]} %{NUMBER:[nginx][access][body_sent][bytes]} \"%{DATA:[nginx][access][referrer]}\" \"%{DATA:[nginx][access][agent]}\" %{NUMBER:[nginx][access][request][length]} %{NUMBER:[nginx][access][request][time]} \[%{DATA:[nginx][access][proxy][upstream_name]}\] \[%{DATA:[nginx][access][proxy][alternative_upstream_name]}\] %{NOTSPACE:[nginx][access][upstream_addr]} %{NUMBER:[nginx][access][upstream][response_length]} %{NUMBER:[nginx][access][upstream][response_time]} %{NUMBER:[nginx][access][upstream][response_status]} %{NOTSPACE:[nginx][access][request_id]}"] }
        remove_field => "message"
  }
  mutate {
        add_field => { "read_timestamp" => "%{@timestamp}" }
  }
  date {
        match => [ "[nginx][access][time]", "dd/MMM/YYYY:H:m:s Z" ]
        remove_field => "[nginx][access][time]"
  }
  useragent {
        source => "[nginx][access][agent]"
        target => "[nginx][access][user_agent]"
        remove_field => "[nginx][access][agent]"
  }
  geoip {
        source => "[nginx][access][remote_ip]"
        target => "[nginx][access][geoip]"
  }

}

  {{- if .Values.logstash_indexer.code_snippet.enabeld }}
  ruby {
    code => '
      {{- .Values.logstash_indexer.code_snippet.code -}} 
    '
  }
  {{- end }}
 
}

output {

  if [kubernetes][labels][k8s-app] in ["filebeat", "journalbeat", "metricbeat" ] {
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST}"]
      user => "${ELASTICSEARCH_USER:\"\"}"
      password => "${ELASTICSEARCH_PASSWORD:\"\"}"
      index => "beats-%{+YYYY.MM.dd}"
      cacert => "/usr/share/logstash/config/${CA_CERT}"
      ssl => "true"
      ssl_certificate_verification => "false"
      manage_template => true
      template => "/usr/share/logstash/config/beats_template.json"
      template_name => "beats_1"
      template_overwrite => true
      ilm_enabled => "false"
      document_id => "%{[@metadata][_id]}"
    }
  } else {  
  # all other containers stdout and stderr go to container ES index
    elasticsearch {
      hosts => ["${ELASTICSEARCH_HOST}"]
      user => "${ELASTICSEARCH_USER:\"\"}"
      password => "${ELASTICSEARCH_PASSWORD:\"\"}"
      index => "containers-%{+YYYY.MM.dd}"
      cacert => "/usr/share/logstash/config/${CA_CERT}"
      ssl => "true"
      ssl_certificate_verification => "false"
      manage_template => true
      template => "/usr/share/logstash/config/containers_template.json"
      template_name => "containers_1"
      template_overwrite => true
      ilm_enabled => "false"
      document_id => "%{[@metadata][_id]}"
    }
  }
}
