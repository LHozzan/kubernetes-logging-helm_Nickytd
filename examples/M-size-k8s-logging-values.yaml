#Scaled configuration suitbale for load < 1 000 000 documents per minute
#Each components in the setup is running in HA mode with at least 2 instances
#Runs stable on 3 nodes ( 4 VCPUs and 16GB RAM - ) Standard_D4_v3 - Azure, c5.2xlarge AWS
elasticsearch:
  index_shards: 1
  index_replicas: 1
  retention_days: 7

client:
  replicas: 2
  heap_size: 512m
  resources:
    requests:
      memory: 1Gi
    limits:
      memory: 1Gi      

master:
  minimum_nodes: 2
  replicas: 2
  heap_size: 512m
  resources:
    requests:
      memory: 1Gi
    limits:
      memory: 1Gi  
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: type
            operator: In
            values:
            - master
        topologyKey: kubernetes.io/hostname    
data:
  replicas: 2
  heap_size: 3g
  resources:
    requests:
      memory: 6Gi
    limits:
      memory: 6Gi
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: type
            operator: In
            values:
            - data
        topologyKey: kubernetes.io/hostname     

kafka:
  enabled: true
  replicas: 2
  heap_size: 1g
  resources:
    requests:
      memory: 2Gi
    limits:
      memory: 2Gi  
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: type
            operator: In
            values:
            - kafka
        topologyKey: kubernetes.io/hostname     

zookeeper:
  replicas: 3
  heap_size: 128M
  resources:
    requests:
      memory: 300Mi
    limits:
      memory: 300Mi
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: type
            operator: In
            values:
            - zk
        topologyKey: kubernetes.io/hostname     

kibana:
  resources:
    requests:
      memory: 3Gi
    limits:
      memory: 3Gi  

logstash_indexer:
  replicas: 2
  heap_size: 1g
  resources:
    requests:
      memory: 2Gi
    limits:
      memory: 2Gi  

journalbeat:
  resources:
    requests:
      memory: 250Mi
    limits:
      memory: 250Mi

filebeat:
  resources:
    requests:
      memory: 250Mi
    limits:
      memory: 250Mi