input {
{{- if .Values.kafka.enabled }}
  
  kafka {
    bootstrap_servers => ["${KAFKA_BOOTSTRAP_SERVERS}"]
    topics => ["containers"]
    client_id => "${HOSTNAME}-contaienrs"
    group_id => "containers"
    auto_offset_reset => "latest"
    consumer_threads => 10
  }

{{ else }}  

  beats {
    port => 5044
  }
    
{{- end }}

}

filter {
  #all messages from the kafka topics are in json format
  {{- if .Values.kafka.enabled }}
    json {
      skip_on_invalid_json => false
      source => "message"
    }
  {{- end }}

  #remove ANSI Color bytes
  mutate {
    gsub => ["message", "\x1B\[([0-9]{1,2}(;[0-9]{1,2})?)?[m|K]", ""]
  }

  #all application json formated logs can be parsed
  # we parse the payload of the message field for json
  {{- if .Values.logstash_indexer.json_messages }}
    json {
      skip_on_invalid_json => false
      source => "message"
      add_tag => [ "json_parsed_successful" ]
    }
  {{- end }}  



}

output {
  
  # all other containers stdout and stderr go to container ES index
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST}"]
    user => "${ELASTICSEARCH_USER:\"\"}"
    password => "${ELASTICSEARCH_PASSWORD:\"\"}"
    index => "containers-%{+YYYY.MM.dd}"
    cacert => "/usr/share/logstash/config/${CA_CERT}"
    ssl => "true"
    manage_template => true
    template => "/usr/share/logstash/config/containers_template.json"
    template_name => "containers_1"
    template_overwrite => true
    ilm_enabled => "false"
    document_id => "%{[@metadata][_id]}"
  }
  
}
