input {

{{- if .Values.kafka.enabled }}
  
  kafka {
    bootstrap_servers => ["${KAFKA_BOOTSTRAP_SERVERS}"]
    topics => ["journals"]
    client_id => "${HOSTNAME}-journals"
    group_id => "journals"
    auto_offset_reset => "latest"
    consumer_threads => 10
    max_partition_fetch_bytes => '15728640'
  } 

{{ else }}  

  beats {
    port => 5045
  } 

{{- end }}

}

filter {
  #all messages from journalbeats are in json format
  json {
    skip_on_invalid_json => false
    source => "message"
  }
  
  #use beats generated id
  mutate {
    add_field => { "id" => "%{[@metadata][_id]}" }
  }

}
output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOST}"]
    user => "${ELASTICSEARCH_USER:\"\"}"
    password => "${ELASTICSEARCH_PASSWORD:\"\"}"       
    index => "journals-%{+YYYY.MM.dd}"
    cacert => "/usr/share/logstash/config/${CA_CERT}"
    ssl => "true"
    manage_template => true
    template => "/usr/share/logstash/config/journals_template.json"
    template_name => "journals_1"
    template_overwrite => true
    ilm_enabled => "false"
    document_id => "%{id}"
  }
}
