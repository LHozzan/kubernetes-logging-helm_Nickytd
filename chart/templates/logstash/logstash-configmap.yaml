{{- if and .Values.kafka.enabled .Values.logstash.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name}}-logstash
  labels: {{ include "logging.labels" . | indent 4 }}
data:
  pipelines.yml: |-
    - pipeline.id: distributor
      path.config: /usr/share/logstash/pipeline/{00_input,01_filter,02_distributor}.conf
{{- range $path, $bytes := .Files.Glob "index-pipelines/*-pipeline.conf" }}
    - pipeline.id: {{ printf "%s" (base $path) }}
      path.config: {{ printf "%s%s" "/usr/share/logstash/pipeline/" (base $path) }}
{{ end }}

  log4j2.properties: |-
    status = error
    name = LogstashPropertiesConfig

    appender.console.type = Console
    appender.console.name = plain_console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %m%n

    appender.json_console.type = Console
    appender.json_console.name = json_console
    appender.json_console.layout.type = JSONLayout
    appender.json_console.layout.compact = true
    appender.json_console.layout.eventEol = true

    rootLogger.level = ${sys:ls.log.level}

    rootLogger.appenderRef.console.ref = ${sys:ls.log.format}_console

    logger.opensearch_output.name = logstash.outputs.opensearch
    logger.opensearch_output.level = warn

    logger.inputs_kafka.name=logstash.inputs.kafka
    logger.inputs_kafka.level=warn

    #slowlog.threshold.warn: 2s
    #slowlog.threshold.info: 1s
    #slowlog.threshold.debug: 500ms
    #slowlog.threshold.trace: 100ms
    
    #logger.inputs.name=logstash.inputs.file
    #logger.inputs.level=warn
    #logger.outputs.name=logstash.outputs.kafka
    #logger.outputs.level=debug
    #logger.pipeline.name=logstash.pipeline
    #logger.pipeline.level=debug
    #logger.grok.name=logstash.filters.grok
    #logger.grok.level=debug
    #logger.mutate.name=logstash.filters.mutate
    #logger.mutate.level=debug

  logstash.yml: |-
    http.host: "0.0.0.0"
    path.settings: /usr/share/logstash/config

    queue.type: persisted
    queue.drain: true

    pipeline.batch.size: 1000
    pipeline.workers: 10
    pipeline.ecs_compatibility: disabled

    log.format: plain
    log.level: warn

    config.reload.automatic: true
 

  jvm.options: |-
    ## JVM configuration

    # Xms represents the initial size of total heap space
    # Xmx represents the maximum size of total heap space

    -Xms1g
    -Xmx1g

    ################################################################
    ## Expert settings
    ################################################################
    ##
    ## All settings below this section are considered
    ## expert settings. Don't tamper with them unless
    ## you understand what you are doing
    ##
    ################################################################

    ## GC configuration
    8-13:-XX:+UseConcMarkSweepGC
    8-13:-XX:CMSInitiatingOccupancyFraction=75
    8-13:-XX:+UseCMSInitiatingOccupancyOnly

    ## Locale
    # Set the locale language
    #-Duser.language=en

    # Set the locale country
    #-Duser.country=US

    # Set the locale variant, if any
    #-Duser.variant=

    ## basic

    # set the I/O temp directory
    #-Djava.io.tmpdir=$HOME

    # set to headless, just in case
    -Djava.awt.headless=true

    # ensure UTF-8 encoding by default (e.g. filenames)
    -Dfile.encoding=UTF-8

    # use our provided JNA always versus the system one
    #-Djna.nosys=true

    # Turn on JRuby invokedynamic
    -Djruby.compile.invokedynamic=true
    # Force Compilation
    -Djruby.jit.threshold=0
    # Make sure joni regexp interruptability is enabled
    -Djruby.regexp.interruptible=true

    ## heap dumps

    # generate a heap dump when an allocation from the Java heap fails
    # heap dumps are created in the working directory of the JVM
    -XX:+HeapDumpOnOutOfMemoryError

    # specify an alternative path for heap dumps
    # ensure the directory exists and has sufficient space
    #-XX:HeapDumpPath=${LOGSTASH_HOME}/heapdump.hprof

    ## GC logging
    #-XX:+PrintGCDetails
    #-XX:+PrintGCTimeStamps
    #-XX:+PrintGCDateStamps
    #-XX:+PrintClassHistogram
    #-XX:+PrintTenuringDistribution
    #-XX:+PrintGCApplicationStoppedTime

    # log GC status to a file with time stamps
    # ensure the directory exists
    #-Xloggc:${LS_GC_LOG_FILE}

    # Entropy source for randomness
    -Djava.security.egd=file:/dev/urandom

    # Copy the logging context from parent threads to children
    -Dlog4j2.isThreadContextMapInheritable=true

    17-:--add-opens java.base/sun.nio.ch=ALL-UNNAMED
    17-:--add-opens java.base/java.io=ALL-UNNAMED

  startup.options: |-
    ################################################################################
    # These settings are ONLY used by $LS_HOME/bin/system-install to create a custom
    # startup script for Logstash and is not used by Logstash itself. It should
    # automagically use the init system (systemd, upstart, sysv, etc.) that your
    # Linux distribution uses.
    #
    # After changing anything here, you need to re-run $LS_HOME/bin/system-install
    # as root to push the changes to the init script.
    ################################################################################

    # Override Java location
    #JAVACMD=/usr/bin/java

    # Set a home directory
    LS_HOME=/usr/share/logstash

    # logstash settings directory, the path which contains logstash.yml
    LS_SETTINGS_DIR=/etc/logstash

    # Arguments to pass to logstash
    LS_OPTS="--path.settings ${LS_SETTINGS_DIR}"

    # Arguments to pass to java
    LS_JAVA_OPTS=""

    # pidfiles aren't used the same way for upstart and systemd; this is for sysv users.
    LS_PIDFILE=/var/run/logstash.pid

    # user and group id to be invoked as
    LS_USER=logstash
    LS_GROUP=logstash

    # Enable GC logging by uncommenting the appropriate lines in the GC logging
    # section in jvm.options
    LS_GC_LOG_FILE=/var/log/logstash/gc.log

    # Open file limit
    LS_OPEN_FILES=16384

    # Nice level
    LS_NICE=19

    # Change these to have the init script named and described differently
    # This is useful when running multiple instances of Logstash on the same
    # physical box or vm
    SERVICE_NAME="logstash"
    SERVICE_DESCRIPTION="logstash"

    # If you need to run a command or script before launching Logstash, put it
    # between the lines beginning with `read` and `EOM`, and uncomment those lines.
    ###
    ## read -r -d '' PRESTART << EOM
    ## EOM

{{- end }}